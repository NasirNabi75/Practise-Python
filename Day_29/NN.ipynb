{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Variables\" data-toc-modified-id=\"Variables-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Variables</a></span></li><li><span><a href=\"#Forward-Propagation\" data-toc-modified-id=\"Forward-Propagation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Forward Propagation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Variables\" data-toc-modified-id=\"Variables-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Variables</a></span></li></ul></li><li><span><a href=\"#Backpropagation\" data-toc-modified-id=\"Backpropagation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Backpropagation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Variables\" data-toc-modified-id=\"Variables-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Variables</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "|Code Symbol | Math Symbol | Definition | Dimensions\n",
    "| :-: | :-: | :-: | :-: |\n",
    "|X|$$X$$|Input Data, each row is an example| (numExamples, inputLayerSize)|\n",
    "|y |$$y$$|target data|(numExamples, outputLayerSize)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say you want to predict some output value y, given some input value X. For example, maybe you want to predict your score on a test based on how many hours you sleep and how many hours you study the night before. To use a machine learning approach, we first need some data. Let’s say for the last three tests, you recorded your number of hours of studying, your number of hours sleeping, and your score on the test. We'll use the programming language python to store our data in 2-dimensional numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# X = (hours sleeping, hours studying), y = Score on test\n",
    "X = np.array(([3,5], [5,1], [10,2]), dtype=float)\n",
    "y = np.array(([75], [82], [93]), dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some data, we’re going to use it to train a model to predict how you will do on your next test, based on how many hours you sleep and how many hours you study. This is called a supervised regression problem. It’s supervised because our examples have inputs and outputs. It’s a regression problem because we’re predicting your test score, which is a continuous output. If we we’re predicting your letter grade, this would be called a classification problem, and not a regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are an overwhelming number of models within machine learning, here we’re going to use a particularly interesting one called an artificial neural network. \n",
    "\n",
    "Before we throw our data into the model, we need to account for the differences in the units of our data. Both of our inputs are in hours, but our output is a test score, scaled between 0 and 100. Neural networks are smart, but not smart enough to guess the units of our data. It’s kind of like asking our model to compare apples to oranges, where most learning models really only want to compare apples to apples. The solution is to scale our data, this way our model only sees standardized units. Here, we're going to take advantage of the fact that all of our data is positive, and simply divide by the maximum value for each variable, effectively scaling the result between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100 #Max test score is 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build our Neural Net. We know our network must have 2 inputs and 1 output, because these are the dimensions of our data. We’ll call our output y hat, because it’s an estimate of y, but not the same as y. Any layer between our input and output layer is called a hidden layer. Recently, researchers have built networks with many many hidden layers. These are known as a deep belief networks, giving rise to the term deep learning. Here, we’re going to use 1 hidden layer with 3 hidden units, but if we wanted to build a deep neural network, we would just stack a bunch of layers together.\n",
    "\n",
    "\"img please\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In neural net visuals, circles represent neurons and lines represent synapses. Synapses have a really simple job, they take a value from their input, multiply it by a specific weight, and output the result. Neurons are a little more complicated. Their job is to add together the outputs of all their synapses, and apply an activation function. Certain activation functions allow neural nets to model complex non-linear patterns, that simpler models may miss. For our neural net, we’ll use sigmoid activation functions. Next, we'll build out our neural net in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "|Code Symbol | Math Symbol | Definition | Dimensions\n",
    "| :-: | :-: | :-: | :-: |\n",
    "|X|$$X$$|Input Data, each row in an example| (numExamples, inputLayerSize)|\n",
    "|y |$$y$$|target data|(numExamples, outputLayerSize)|\n",
    "|W1 | $$W^{(1)}$$ | Layer 1 weights | (inputLayerSize, hiddenLayerSize) |\n",
    "|W2 | $$W^{(2)}$$ | Layer 2 weights | (hiddenLayerSize, outputLayerSize) |\n",
    "|z2 | $$z^{(2)}$$ | Layer 2 activation | (numExamples, hiddenLayerSize) |\n",
    "|a2 | $$a^{(2)}$$ | Layer 2 activity | (numExamples, hiddenLayerSize) |\n",
    "|z3 | $$z^{(3)}$$ | Layer 3 activation | (numExamples, outputLayerSize) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network has 2 inputs, 3 hidden units, and 1 output. These are examples of hyperparameters. Hyperparameters are constants that establish the structure and behavior of a neural network, but are not updated as we train the network. Our learning algorithm is not capable of, for example, deciding that it needs another hidden unit, this is something that WE must decide on before training. What a neural network does learn are parameters, specifically the weights on the synapses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propagate inputs though network\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each input value, or element in matrix X, needs to be multiplied by a corresponding weight and then added together with all the other results for each neuron. This is a complex operation, but if we take the three outputs we're looking for as a single row of a matrix, and place all our individual weights into a matrix of weights, we can create the exact behavior we need by multiplying our input data matrix by our weight matrix. Using matrix multiplication allows us to pass multiple inputs through at once by simply adding rows to the matrix X. From here on out, we'll refer to these matrics as X, W one, and z two, where z two the activity of our second layer. Notice that each entry in z is a sum of weighted inputs to each hidden neuron. Z is of size 3 by 3, one row for each example, and one column for each hidden unit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our first official formula, $z^{(2)} = XW^{(1)}$. Matrix notation is really nice here, becuase it allows us to express the complex underlying process in a single line!\n",
    "\n",
    "$$\n",
    "z^{(2)} = XW^{(1)} \\tag{1}\\\\\n",
    "$$\n",
    "Now that we have the activities for our second layer, z two, we need to apply the activation function. We'll independently apply the function to each entry in matrix z using a python method for this called sigmoid, because we’re using a sigmoid as our activation function. Using numpy is really nice here, because we can pass in a scalar, vector, or matrix, Numpy will apply the activation function element-wise, and return a result of the same dimension as it was given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "    return 1/(1+np.exp(-z))\n",
    "testInput = np.arange(-6,6,0.01)\n",
    "plot(testInput, sigmoid(testInput), linewidth= 2)\n",
    "grid(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We now have our second formula for forward propagation, using f to denote our activation function, we can write that a two, our second layer activity, is equal to f of z two. a two will be a matrix of the same size as z two, 3 by 3.\n",
    " $$\n",
    "a^{(2)} = f(z^{(2)}) \\tag{2}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish forward propagation we need to propagate a two all the way to the output, yhat. We've already done the heavy lifting in the previous layer, so all we have to do now is multiply a two by our senond layer weights W2 and apply one more activation funcion. W2 will be of size 3x1, one weight for each synapse. Multiplying a2, a 3 by 3, by W2, a 3 by 1 results in a 3 by 1 matrix z three, the activity or our third layer. z3 has three activity values, one for each example. Last but not least, we'll apply our activation function to z three yielding our official estimate of your test score, yHat.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z^{(3)} = a^{(2)}W^{(2)} \\tag{3}\\\\\n",
    "$$\n",
    "$$\n",
    "\\hat{y} = f(z^{(3)}) \\tag{4}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We need to implement our forward propagation formulas in python. First we'll initialize our weight matrices in our init method. For starting values, we'll use random numbers. We need to implement our forward propagation formulas in python. First we'll initialize our weight matrices in our init method. For starting values, we'll use random numbers.\n",
    "We'll implement forward propagation in our forward method, using numpy's built in dot method for matrix multiplication and our own sigmoid method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propagate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "each error value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training neural net = minimizing cost value\n",
    "to reduce cost we need to change the w value\n",
    "y gradient decient ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "|Code Symbol | Math Symbol | Definition | Dimensions\n",
    "| :-: | :-: | :-: | :-: |\n",
    "|X|$$X$$|Input Data, each row in an example| (numExamples, inputLayerSize)|\n",
    "|y |$$y$$|target data|(numExamples, outputLayerSize)|\n",
    "|W1 | $$W^{(1)}$$ | Layer 1 weights | (inputLayerSize, hiddenLayerSize) |\n",
    "|W2 | $$W^{(2)}$$ | Layer 2 weights | (hiddenLayerSize, outputLayerSize) |\n",
    "|z2 | $$z^{(2)}$$ | Layer 2 activation | (numExamples, hiddenLayerSize) |\n",
    "|a2 | $$a^{(2)}$$ | Layer 2 activity | (numExamples, hiddenLayerSize) |\n",
    "|z3 | $$z^{(3)}$$ | Layer 3 activation | (numExamples, outputLayerSize) |\n",
    "|J | $$J$$ | Cost | (1, outputLayerSize) |\n",
    "|dJdz3 | $$\\frac{\\partial J}{\\partial z^{(3)} } = \\delta^{(3)}$$ | Partial derivative of cost with respect to $z^{(3)}$ | (numExamples,outputLayerSize)|\n",
    "|dJdW2|$$\\frac{\\partial J}{\\partial W^{(2)}}$$|Partial derivative of cost with respect to $W^{(2)}$|(hiddenLayerSize, outputLayerSize)|\n",
    "|dz3dz2|$$\\frac{\\partial z^{(3)}}{\\partial z^{(2)}}$$|Partial derivative of $z^{(3)}$ with respect to $z^{(2)}$|(numExamples, hiddenLayerSize)|\n",
    "|dJdW1|$$\\frac{\\partial J}{\\partial W^{(1)}}$$|Partial derivative of cost with respect to $W^{(1)}$|(inputLayerSize, hiddenLayerSize)|\n",
    "|delta2|$$\\delta^{(2)}$$|Backpropagating Error 2|(numExamples,hiddenLayerSize)|\n",
    "|delta3|$$\\delta^{(3)}$$|Backpropagating Error 1|(numExamples,outputLayerSize)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we decided to use gradient descent to train our Neural Network, so it could make better predictions of your score on a test based on how many hours you slept, and how many hours you studied the night before. To perform gradient descent, we need an equation and some code for our gradient, dJ/dW.\n",
    "Our weights, W, are spread across two matrices, W1 and W2. We’ll separate our dJ/dW computation in the same way, by computing dJdW1 and dJdW2 independently. We should have just as many gradient values as weight values, so when we’re done, our matrices dJdW1 and dJdW2 will be the same size as W1 and W2.\n",
    "\n",
    "\n",
    "We can now evaluate our derivative. The power rule tells us to bring down our exponent, 2, and multiply. To finish our derivative, we’ll need to apply the chain rule.\n",
    "\n",
    "The chain rule tells us how to take the derivative of a function inside of a function, and generally says we take the derivative of the outside function and then multiply it by the derivative of the inside function.\n",
    "\n",
    "One way to express the chain rule is as the product of derivatives, this will come in very handy as we progress through backpropagation. In fact, a better name for backpropagation might be: don’t stop doing the chain rule. ever.\n",
    "\n",
    "We’ve taken the derivative of the outside of our cost function - now we need to multiply it by the derivative of the inside.\n",
    "\n",
    "Y is just our test scores, which won’t change, so the derivative of y, a constant, with respect to W two is 0! yHat, on the other hand, does change with respect to W two, so we’ll apply the chain rule and multiply our results by minus dYhat/dW2.\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(2)}} = -(y-\\hat{y}) \\frac{\\partial \\hat{y}}{\\partial W^{(2)}}\n",
    "$$\n",
    "\n",
    "\n",
    "We now need to think about the derivative of yHat with respect to W2. Equation 4 tells us that yHat is our activation function of z3, so we it will be helpful to apply the chain rule again to break dyHat/dW2 into dyHat/dz3 times dz3/dW2. \n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(2)}} = \n",
    "-(y-\\hat{y})\n",
    "\\frac{\\partial \\hat{y}}{\\partial z^{(3)}}  \n",
    "\\frac{\\partial z^{(3)}}{\\partial W^{(2)}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "To find the rate of change of yHat with respect to z3, we need to differentiate our sigmoid activation function with respect to z. \n",
    "\n",
    "$$\n",
    "f(z) = \\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f^\\prime(z) = \\frac{e^{-z}}{(1+e^{-z})^2}\n",
    "$$\n",
    "\n",
    "\n",
    "Now is a good time to add a new python method for the derivative of our sigmoid function, sigmoid Prime. Our derivative should be the largest where our sigmoid function is the steepest, at the value z equals zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe592a430b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "     #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def sigmoidPrime(z):\n",
    "    #Derivative of sigmoid function\n",
    "    return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "\n",
    "testValues = np.arange(-5,5,0.01)\n",
    "plot(testValues, sigmoid(testValues), linewidth=2)\n",
    "plot(testValues, sigmoidPrime(testValues), linewidth=2)\n",
    "grid(1)\n",
    "legend(['sigmoid', 'sigmoidPrime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now replace dyHat/dz3 with f prime of z 3.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(2)}}= \n",
    "-(y-\\hat{y}) f^\\prime(z^{(3)}) \\frac{\\partial z^{(3)}}{\\partial W^{(2)}}\n",
    "$$\n",
    "\n",
    "Our final piece of the puzzle is dz3dW2, this term represents the change of z, our third layer activity, with respect to the weights in the second layer.\n",
    "\n",
    "\n",
    "Z three is the matrix product of our activities, a two, and our weights, w two. The activities from layer two are multiplied by their correspond weights and added together to yield z3. If we focus on a single synapse for a moment, we see a simple linear relationship between W and z, where a is the slope. So for each synapse, dz/dW(2) is just the activation, a on that synapse!\n",
    "\n",
    "\n",
    "$$\n",
    "z^{(3)} = a^{(2)}W^{(2)} \\tag{3}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We determined that dz3/dW2 is equal to the activity of each synapse. Each value in delta 3 needs to be multiplied by each activity. We can achieve this by transposing a2 and matrix multiplying by delta3. \n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(2)}} = \n",
    "(a^{(2)})^T\\delta^{(3)}\\tag{6}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta^{(3)} = -(y-\\hat{y}) f^\\prime(z^{(3)}) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part of NN Class (won't work alone, needs to be included in class as \n",
    "# shown in below and in partFour.py):\n",
    "\n",
    "def costFunctionPrime(self, X, y):\n",
    "    #Compute derivative with respect to W and W2 for a given X and y:\n",
    "    self.yHat = self.forward(X)\n",
    "\n",
    "    delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
    "    dJdW2 = np.dot(self.a2.T, delta3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We have one final term to compute: dJ/dW1. The derivation begins the same way, computing the derivative through our final layer: first dJ/dyHat, then dyHat/dz3, and we called these two taken together form our backpropagating error, delta3. We now take the derivative “across” our synapses, this is a little different from out job last time, computing the derivative with respect to the weights on our synapses. \n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(1)}} = (y-\\hat{y})\n",
    "\\frac{\\partial \\hat{y}}{\\partial W^{(1)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(1)}} = (y-\\hat{y})\n",
    "\\frac{\\partial \\hat{y}}{\\partial z^{(3)}}\n",
    "\\frac{\\partial z^{(3)}}{\\partial W^{(1)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(1)}} = -(y-\\hat{y}) f^\\prime(z^{(3)}) \\frac{\\partial z^{(3)}}{\\partial W^{(1)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(3)}}{\\partial W^{(1)}} = \\frac{\\partial z^{(3)}}{\\partial a^{(2)}}\\frac{\\partial a^{(2)}}{\\partial W^{(1)}}\n",
    "$$\n",
    "\n",
    "\n",
    "There’s still a nice linear relationship along each synapse, but now we’re interested in the rate of change of z(3) with respect to a(2). Now the slope is just equal to the weight value for that synapse. We can achieve this mathematically by multiplying by W(2) transpose. \n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(1)}} = \\delta^{(3)} \n",
    "(W^{(2)})^{T}\n",
    "\\frac{\\partial a^{(2)}}{\\partial W^{(1)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(1)}} = \\delta^{(3)} \n",
    "(W^{(2)})^{T}\n",
    "\\frac{\\partial a^{(2)}}{\\partial z^{(2)}}\n",
    "\\frac{\\partial z^{(2)}}{\\partial W^{(1)}}\n",
    "$$\n",
    "\n",
    "\n",
    "Our next term to work on is da(2)/dz(2) – this step is just like the derivative across our layer 3 neurons, so we can just multiply by f prime(z2). \n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(1)}} = \\delta^{(3)} \n",
    "(W^{(2)})^{T}\n",
    "f^\\prime(z^{(2)})\n",
    "\\frac{\\partial z^{(2)}}{\\partial W^{(1)}}\n",
    "$$\n",
    "Our final computation here is dz2/dW1. This is very similar to our dz3/dW2 computation, there is a simple linear relationship on the synapses between z2 and w1, in this case though, the slope is the input value, X. We can use the same technique as last time by multiplying by X transpose, effectively applying the derivative and adding our dJ/dW1’s together across all our examples. \n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(1)}} = \n",
    "X^{T}\n",
    "\\delta^{(3)} \n",
    "(W^{(2)})^{T}\n",
    "f^\\prime(z^{(2)})\n",
    "$$\n",
    "Or:\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{(1)}} = \n",
    "X^{T}\\delta^{(2)} \\tag{7}\n",
    "$$\n",
    "$$\n",
    "\\delta^{(2)} = \\delta^{(3)} \n",
    "(W^{(2)})^{T}\n",
    "f^\\prime(z^{(2)})\n",
    "$$\n",
    "All that’s left is to code this equation up in python. What’s cool here is that if we want to make a deeper neural network, we could just stack a bunch of these operations together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole Class with additions:\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propogate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoidPrime(self,z):\n",
    "        #Gradient of sigmoid\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5*sum((y-self.yHat)**2)\n",
    "        return J\n",
    "        \n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forward(X)\n",
    "        \n",
    "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        dJdW1 = np.dot(X.T, delta2)  \n",
    "        \n",
    "        return dJdW1, dJdW2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how should we change our W’s to decrease our cost? We can now compute dJ/dW, which tells us which way is uphill in our 9 dimensional optimization space. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00169774, -0.00106138, -0.00802348],\n",
       "       [ 0.00025955,  0.0001645 ,  0.00116819]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "cost1 = NN.costFunction(X,y)\n",
    "dJdW1, dJdW2 = NN.costFunctionPrime(X,y)\n",
    "dJdW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00212579],\n",
       "       [-0.00416775],\n",
       "       [-0.00349208]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJdW2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we move this way by adding a scalar times our derivative to our weights, our cost will increase, and if we do the opposite, subtract our gradient from our weights, we will move downhill and reduce our cost. This simple step downhill is the core of gradient descent and a key part of how even very sophisticated learning algorithms are trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007615993062024447 0.007946335124043101\n"
     ]
    }
   ],
   "source": [
    "scalar = 3\n",
    "NN.W1 = NN.W1 + scalar*dJdW1\n",
    "NN.W2 = NN.W2 + scalar*dJdW2\n",
    "cost2 = NN.costFunction(X,y)\n",
    "print(cost1, cost2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007946335124043101 0.007579346424289521\n"
     ]
    }
   ],
   "source": [
    "dJdW1, dJdW2 = NN.costFunctionPrime(X,y)\n",
    "NN.W1 = NN.W1 - scalar*dJdW1\n",
    "NN.W2 = NN.W2 - scalar*dJdW2\n",
    "cost3 = NN.costFunction(X, y)\n",
    "print(cost2, cost3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add helper functions to our neural network class: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propogate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoidPrime(self,z):\n",
    "        #Gradient of sigmoid\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5*sum((y-self.yHat)**2)\n",
    "        return J\n",
    "        \n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forward(X)\n",
    "        \n",
    "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        dJdW1 = np.dot(X.T, delta2)  \n",
    "        \n",
    "        return dJdW1, dJdW2\n",
    "    \n",
    "    #Helper Functions for interacting with other classes:\n",
    "    def getParams(self):\n",
    "        #Get W1 and W2 unrolled into vector:\n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def setParams(self, params):\n",
    "        #Set W1 and W2 using single paramater vector.\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayerSize * self.inputLayerSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayerSize))\n",
    "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayerSize, self.outputLayerSize))\n",
    "        \n",
    "    def computeGradients(self, X, y):\n",
    "        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same approach to numerically evaluate the gradient of our neural network. It’s a little more complicated this time, since we have 9 gradient values, and we’re interested in the gradient of our cost function. We’ll make things simpler by testing one gradient at a time. We’ll “perturb” each weight - adding epsilon to the current value and  computing the cost function, subtracting epsilon from the current value and computing the cost function, and then computing the slope between these two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNumericalGradient(N, X, y):\n",
    "        paramsInitial = N.getParams()\n",
    "        numgrad = np.zeros(paramsInitial.shape)\n",
    "        perturb = np.zeros(paramsInitial.shape)\n",
    "        e = 1e-4\n",
    "\n",
    "        for p in range(len(paramsInitial)):\n",
    "            #Set perturbation vector\n",
    "            perturb[p] = e\n",
    "            N.setParams(paramsInitial + perturb)\n",
    "            loss2 = N.costFunction(X, y)\n",
    "            \n",
    "            N.setParams(paramsInitial - perturb)\n",
    "            loss1 = N.costFunction(X, y)\n",
    "\n",
    "            #Compute Numerical Gradient\n",
    "            numgrad[p] = (loss2 - loss1) / (2*e)\n",
    "\n",
    "            #Return the value we changed to zero:\n",
    "            perturb[p] = 0\n",
    "            \n",
    "        #Return Params to original value:\n",
    "        N.setParams(paramsInitial)\n",
    "\n",
    "        return numgrad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04780163 -0.00485852  0.0243479  -0.0290957  -0.00285684  0.01421983\n",
      " -0.0844315  -0.10063828 -0.09916792]\n",
      "[-0.04780163 -0.00485852  0.0243479  -0.0290957  -0.00285684  0.01421983\n",
      " -0.0844315  -0.10063828 -0.09916792]\n",
      "1.7852457247969946e-10\n"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "numgrad = computeNumericalGradient(NN, X, y)\n",
    "print(numgrad)\n",
    "grad = NN.computeGradients(X,y)\n",
    "print(grad)\n",
    "print(norm(grad-numgrad)/norm(grad+numgrad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "class trainer(object):\n",
    "    def __init__(self, N):\n",
    "        #Make Local reference to network:\n",
    "        self.N = N\n",
    "        \n",
    "    def callbackF(self, params):\n",
    "        self.N.setParams(params)\n",
    "        self.J.append(self.N.costFunction(self.X, self.y))   \n",
    "        \n",
    "    def costFunctionWrapper(self, params, X, y):\n",
    "        self.N.setParams(params)\n",
    "        cost = self.N.costFunction(X, y)\n",
    "        grad = self.N.computeGradients(X,y)\n",
    "        \n",
    "        return cost, grad\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        #Make an internal variable for the callback function:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        #Make empty list to store costs:\n",
    "        self.J = []\n",
    "        \n",
    "        params0 = self.N.getParams()\n",
    "\n",
    "        options = {'maxiter': 200, 'disp' : True}\n",
    "        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS', \\\n",
    "                                 args=(X, y), options=options, callback=self.callbackF)\n",
    "\n",
    "        self.N.setParams(_res.x)\n",
    "        self.optimizationResults = _res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = trainer(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 58\n",
      "         Function evaluations: 63\n",
      "         Gradient evaluations: 63\n"
     ]
    }
   ],
   "source": [
    "T.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cost')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(T.J)\n",
    "grid(1)\n",
    "xlabel('Iterations')\n",
    "ylabel('Cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 3.25061789e-07, -1.37841880e-08,  1.72807721e-07],\n",
       "        [ 2.03083557e-06, -3.70859439e-06,  1.23765297e-06]]),\n",
       " array([[9.08800769e-07],\n",
       "        [2.77423588e-07],\n",
       "        [1.14221615e-06]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.costFunctionPrime(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75003081],\n",
       "       [0.81997909],\n",
       "       [0.92999513]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.forward(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
